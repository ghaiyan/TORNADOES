{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1182, 1182)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "hic = np.loadtxt('/data/ghy_data/GM12878/chr19_50000.hic')#Hi-c data\n",
    "print(hic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "hic = np.loadtxt('/data/ghy_data/GM12878/chr19_50000.hic')#Hi-c data\n",
    "subcomparts = np.loadtxt('output/GM12878/50kb_TAD/chr19_subcomparts.txt')\n",
    "tad = np.loadtxt('output/GM12878/50kb_TAD/chr19.txt')#此处用四列的TAD数据\n",
    "\n",
    "outpath = \"output/GM12878/hypergraph/hyperedge.txt\"\n",
    "i = 0\n",
    "j = 0\n",
    "nodes = []\n",
    "\n",
    "with open(outpath, \"w\") as out:\n",
    "    while i<len(subcomparts):\n",
    "        start = int(subcomparts[i][0])\n",
    "        end = int(subcomparts[i][2])\n",
    "        while j<len(tad):\n",
    "            if not(tad[j][2] + 3< start or tad[j][0] - end >3) :\n",
    "                nodes.append(j+1)\n",
    "            j = j+1\n",
    "        if len(nodes)>0:\n",
    "            out.write(\"\\t\".join((str(nodes[0]),  str(nodes[-1]))) + \"\\n\")\n",
    "        nodes = []\n",
    "        j = 0\n",
    "        i = i+1\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "hyperedge = np.loadtxt(\"output/GM12878/hypergraph/hyperedge.txt\")\n",
    "tad = np.loadtxt('output/GM12878/50kb_TAD/chr19.txt')#此处用四列的TAD数据\n",
    "outpath = \"output/GM12878/hypergraph/hyperedge_all.txt\"\n",
    "i = 0\n",
    "hyperedge2 = np.array([[0,0]])\n",
    "if hyperedge[0][0]>1:\n",
    "    hyperedge2 = np.array([[1,int(hyperedge[0][0])-1]])\n",
    "\n",
    "while i < len(hyperedge)-1 :\n",
    "    if int(hyperedge[i][1])+1 < int(hyperedge[i+1][0]):\n",
    "        hyperedge2 = np.append(hyperedge2,np.array([[int(hyperedge[i][1])+1,int(hyperedge[i+1][0])-1]]),axis=0)\n",
    "    i= i+1\n",
    "hyperedge2 = np.delete(hyperedge2, 0,0)\n",
    "hyperedge = np.append(hyperedge,hyperedge2,axis=0)\n",
    "hyperedge = np.sort(hyperedge,axis=0)\n",
    "np.savetxt(outpath, np.c_[hyperedge],fmt='%d',delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "hyperedge = np.loadtxt(\"output/GM12878/hypergraph/hyperedge_all.txt\")\n",
    "outpath = \"output/GM12878/hypergraph/hyperedge_flat.txt\"\n",
    "\n",
    "res = []\n",
    "temp = []\n",
    "i = 0\n",
    "\n",
    "while i<len(hyperedge):\n",
    "    temp = list(range(int(hyperedge[i][0])-1,int(hyperedge[i][1])))\n",
    "    for _ in temp:\n",
    "        res.append([_, i])\n",
    "    temp = []\n",
    "    i = i+1\n",
    "\n",
    "res = np.array(res)\n",
    "print(res.shape)\n",
    "\n",
    "np.savetxt(outpath, res, fmt='%d',delimiter='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理A/B区室结果\n",
    "import numpy as np\n",
    "\n",
    "# AB_KR = np.loadtxt('/home/zsc/study/biye/fanc/compartments/IMR90/chr19.txt')\n",
    "A_KR_outpath = 'output/IMR90/AB/A_KR.txt'\n",
    "B_KR_outpath = 'output/IMR90/AB/B_KR.txt'\n",
    "with open('fanc/compartments/GM12878/chr19.txt') as nkFile:\n",
    "    lines = [line.strip().split() for line in nkFile]\n",
    "group = np.array(lines)\n",
    "AB_KR = group[:,4]\n",
    "# print(int(AB_KR[1]))\n",
    "with open(A_KR_outpath, \"w\") as out:\n",
    "    left = -1\n",
    "    for i in range(len(AB_KR)):\n",
    "        if AB_KR[i]>='0' and left==-1:\n",
    "            left = i\n",
    "        elif left>=0 and (AB_KR[i]<'0' or str(AB_KR[i])==\"nan\") :\n",
    "            out.write(\"\\t\".join((str(left+1),str(i))) + \"\\n\")\n",
    "            left=-1\n",
    "    if left>=0:\n",
    "        out.write(\"\\t\".join((str(left+1),str(len(AB_KR)))) + \"\\n\")\n",
    "\n",
    "    # out.close()\n",
    "\n",
    "with open(B_KR_outpath, \"w\") as out:\n",
    "    left = -1\n",
    "    for i in range(len(AB_KR)):\n",
    "        if AB_KR[i]<'0' and left==-1:\n",
    "            left = i\n",
    "        elif left>=0 and (AB_KR[i]>'0' or str(AB_KR[i])==\"nan\") :\n",
    "            out.write(\"\\t\".join((str(left+1),str(i))) + \"\\n\")\n",
    "            left=-1\n",
    "    if left>=0:\n",
    "        out.write(\"\\t\".join((str(left+1),str(len(AB_KR)))) + \"\\n\")\n",
    "\n",
    "    # out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先获取子区室结果\n",
    "# 处理子区室结果\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "A1_outpath = 'output/IMR90/sub-compartment/A1.txt'\n",
    "B1_outpath = 'output/IMR90/sub-compartment/B1.txt'\n",
    "A2_outpath = 'output/IMR90/sub-compartment/A2.txt'\n",
    "B2_outpath = 'output/IMR90/sub-compartment/B2.txt'\n",
    "with open('output/IMR90/sub-compartment/chr19_sub_compartments.bed') as nkFile:\n",
    "    lines = [line.strip().split() for line in nkFile]\n",
    "group = np.array(lines)\n",
    "start = group[:,1]\n",
    "end = group[:,2]\n",
    "AB_KR = group[:,3]\n",
    "with open(A2_outpath, \"w\") as out:\n",
    "    left = -1\n",
    "    for i in range(len(AB_KR)):\n",
    "        if AB_KR[i][:3] == 'A.2' and left==-1:\n",
    "            left = i\n",
    "        elif left>=0 and (AB_KR[i][:3] != 'A.2' or str(AB_KR[i])==\"nan\") :\n",
    "            out.write(\"\\t\".join((str(int((int(start[left])-1)/50000)+1),str(int(int(end[i-1])/50000)))) + \"\\n\")\n",
    "            left=-1\n",
    "    # if left>=0:\n",
    "    #     out.write(\"\\t\".join((str(int((int(start[left])-1)/50000)),str(1172))) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1172,)\n",
      "[[ 0.07408     0.16294     0.10196     0.08117     0.06311   ]\n",
      " [ 0.08814944  0.16272644  0.11364739  0.08288952  0.08109683]\n",
      " [ 0.07420886  0.16294     0.11546627  0.0845498   0.06698602]\n",
      " ...\n",
      " [ 1.86968053  6.27048508  0.41338051  1.31347769  0.07955498]\n",
      " [ 3.4683096  10.11486858  3.07137689  2.63908803  0.27368701]\n",
      " [ 7.8469395  12.31846014  2.28528711  4.38680025  0.02484146]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "def normalization(data):\n",
    "    _range = np.max(data)-np.min(data)\n",
    "    return (data-np.min(data)) / _range\n",
    "\n",
    "data_CTCF = np.load(\n",
    "    'epi/output/IMR90/chr19_50000b_CTCF.npy')\n",
    "data_H3K4me3 = np.load(\n",
    "    'epi/output/IMR90/chr19_50000b_H3K4me3.npy')\n",
    "data_H3K27ac = np.load(\n",
    "    'epi/output/IMR90/chr19_50000b_H3K27ac.npy')\n",
    "data_POLR2A = np.load(\n",
    "    'epi/output/IMR90/chr19_50000b_POLR2A.npy')\n",
    "data_H3K9me3 = np.load(\n",
    "    'epi/output/IMR90/chr19_50000b_H3K9me3.npy')\n",
    "print(data_H3K4me3.shape)\n",
    "feature = np.dstack((data_H3K27ac[:1173], data_H3K4me3[:1173], data_CTCF[:1173], data_POLR2A[:1173],data_H3K9me3[:1173]))\n",
    "print(feature[0])\n",
    "# 特征归一化\n",
    "# feature_norm = []\n",
    "# for j in feature[0]:\n",
    "#     feature_norm.append(normalization(j))\n",
    "# np.savetxt(\"./output/feature_norm/chr\"+str(i)+'.txt',\n",
    "#            feature_norm, fmt=\"%f\", delimiter=' ')\n",
    "np.savetxt(\"epi/output/IMR90/chr19.txt\",feature[0], fmt=\"%f\", delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##19号染色体为例 ##计算每个TAD的特征值 ##TAD内节点特征值的均值\n",
    "def feature_edge(feature_path,out_path):\n",
    "    dataAll = []\n",
    "    single_edge_feature = []\n",
    "    feature_19 = np.loadtxt(feature_path)\n",
    "    data_19 = np.loadtxt('output/IMR90/50kb_TAD/chr19.txt')\n",
    "\n",
    "    f=open('output/IMR90/50kb_TAD/chr19') #此处用二列的TAD数据\n",
    "    for line in f.readlines():\n",
    "        dataSet = []\n",
    "        for i in np.arange(int(line.split()[0]), int(line.split()[1])+1):\n",
    "            dataSet.append(feature_19[i-1])\n",
    "        single_TAD_feature = np.mean(dataSet, axis=0)\n",
    "        dataAll.append(single_TAD_feature)\n",
    "    f.close\n",
    "\n",
    "    feature_norm = []\n",
    "    for j in dataAll:\n",
    "        feature_norm.append(normalization(j))\n",
    "\n",
    "    np.savetxt(out_path, feature_norm, fmt=\"%f\")\n",
    "    # np.savetxt(\"./output/feature_edge/chr19/\"+'5861_PCA.txt',\n",
    "    #            feature_PCA, fmt=\"%f\", delimiter=' ')\n",
    "\n",
    "feature_edge('epi/output/IMR90/chr19.txt','epi/output/IMR90/chr19_TAD.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712.2800679999998 1414.1970250000004 540.1042300000001 577.3991860000001 490.795189\n"
     ]
    }
   ],
   "source": [
    "# ##19号染色体为例 ##计算每个类TAD信号值和\n",
    "def feature_edge(feature_path,out_path):\n",
    "    dataAll = []\n",
    "    single_edge_feature = []\n",
    "    feature_19 = np.loadtxt(feature_path)\n",
    "    data_19 = np.loadtxt('output/IMR90/50kb_TAD/chr19.txt')\n",
    "\n",
    "    f=open('output/IMR90/hypergraph/two/second.txt')\n",
    "    for line in f.readlines():\n",
    "        start = int(line.split()[0])\n",
    "        end = int(line.split()[1])\n",
    "        # if start>=48 and end<=196:\n",
    "        dataSet = []\n",
    "        for i in np.arange(start, end+1):\n",
    "            dataSet.append(feature_19[i-1])\n",
    "        single_TAD_feature = np.sum(dataSet, axis=0)\n",
    "        dataAll.append(single_TAD_feature)\n",
    "    f.close\n",
    "    v_H3K27ac = np.sum(dataAll, axis=0)[0]\n",
    "    v_H3K4me3 = np.sum(dataAll, axis=0)[1]\n",
    "    v_CTCF = np.sum(dataAll, axis=0)[2]\n",
    "    v_POLR2A = np.sum(dataAll, axis=0)[3]\n",
    "    v_H3K9me3 = np.sum(dataAll, axis=0)[4]\n",
    "    return v_H3K27ac,v_H3K4me3,v_CTCF,v_POLR2A,v_H3K9me3\n",
    "\n",
    "v_H3K27ac,v_H3K4me3,v_CTCF,v_POLR2A,v_H3K9me3 = feature_edge('epi/output/IMR90/chr19.txt','output/IMR90/hypergraph/two/chr19_TAD.txt')\n",
    "print(v_H3K27ac,v_H3K4me3,v_CTCF,v_POLR2A,v_H3K9me3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df6c1b9e7f444e82fc3c2ecdf9b72840cb94399d74213e5650c360300c2a75cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
