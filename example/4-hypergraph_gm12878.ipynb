{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load generation.py\n",
    "# generation\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "import sys\n",
    "\n",
    "from hyperg import HyperG\n",
    "\n",
    "def gen_hg(X,with_feature,tad,hyperedge,hyperedge_flat):\n",
    "    \"\"\"\n",
    "    :param X: numpy array, shape = (n_samples, n_features)\n",
    "    :param with_feature: bool, optional(default=False)\n",
    "    :return: instance of HyperG\n",
    "    \"\"\"\n",
    "    \n",
    "    n_nodes = tad.shape[0]\n",
    "    n_edges = hyperedge.shape[0]\n",
    "\n",
    "    node_idx = hyperedge_flat[:,0]\n",
    "    edge_idx = hyperedge_flat[:,1]\n",
    "\n",
    "    values = np.ones(node_idx.shape[0])\n",
    "\n",
    "    H = sparse.coo_matrix((values, (node_idx, edge_idx)), shape=(n_nodes, n_edges))\n",
    "    w = np.ones(n_edges)\n",
    "\n",
    "    if with_feature:\n",
    "        return HyperG(H, w = w, X=X)\n",
    "\n",
    "    return HyperG(H,w = w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111, 3)\n"
     ]
    }
   ],
   "source": [
    "# %load learning.py\n",
    "from sklearn.cluster import k_means\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.utils import check_symmetric, check_random_state\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "from hyperg import HyperG\n",
    "\n",
    "feature = np.loadtxt('epi/output/GM12878/chr19_TAD.txt')\n",
    "print(feature.shape)\n",
    "\n",
    "def spectral_hg_partitioning(hg, n_clusters, assign_labels='kmeans', n_components=None, random_state=None, n_init=10):\n",
    "    \"\"\"\n",
    "    :param hg: instance of HyperG\n",
    "    :param n_clusters: int,\n",
    "    :param assign_labels: str, {'kmeans', 'discretize'}, default: 'kmeans'\n",
    "    :param n_components: int, number of eigen vectors to use for the spectral embedding\n",
    "    :param random_state: int or None (default)\n",
    "    :param n_init: int, number of time the k-means algorithm will be run\n",
    "    with different centroid seeds.\n",
    "    :return: numpy array, shape = (n_samples,), labels of each point\n",
    "    \"\"\"\n",
    "\n",
    "    assert isinstance(hg, HyperG)\n",
    "    assert n_clusters <= hg.num_nodes()\n",
    "\n",
    "    random_state = check_random_state(random_state)\n",
    "\n",
    "    if n_components is None:\n",
    "        n_components = n_clusters\n",
    "\n",
    "    L = hg.laplacian().toarray()\n",
    "    L = check_symmetric(L)\n",
    "\n",
    "    eigenval, eigenvec = eigh(L)\n",
    "    embeddings = eigenvec[:, :n_components]\n",
    "    embeddings = np.concatenate((embeddings, feature), axis=1)\n",
    "    print(embeddings.shape)\n",
    "    if assign_labels == 'kmeans':\n",
    "        _, labels, _ = k_means(embeddings, n_clusters = n_clusters, random_state=random_state,\n",
    "                               n_init=n_init)\n",
    "    else:\n",
    "        labels = SpectralClustering(n_clusters, random_state=random_state).fit(embeddings).labels_\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111, 6)\n",
      "[2 0 0 0 0 0 0 0 1 0 2 2 0 2 2 1 0 0 0 0 1 1 2 1 0 1 0 0 0 0 1 1 0 2 0 0 2\n",
      " 1 2 0 0 0 0 0 0 2 0 0 2 1 2 2 2 2 1 2 2 2 1 1 2 1 2 2 1 0 1 0 0 1 1 1 2 0\n",
      " 1 2 1 0 0 2 1 2 0 1 0 0 1 1 1 1 0 0 2 1 0 2 1 1 0 0 2 1 0 0 2 1 1 2 1 1 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/ghy_data/TORNADOES/TORNADOES/hyperg.py:78: RuntimeWarning: divide by zero encountered in power\n",
      "  dv2 = np.power(self._DV.data.reshape(-1), -0.5)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr,spearmanr\n",
    "\n",
    "TAD = np.loadtxt(\"output/GM12878/50kb_TAD/chr19.txt\")\n",
    "hyperedge = np.loadtxt('output/GM12878/hypergraph/hyperedge_all.txt')\n",
    "hyperedge_flat = np.loadtxt('output/GM12878/hypergraph/hyperedge_flat.txt')\n",
    "\n",
    "hg = gen_hg(None,False,TAD,hyperedge,hyperedge_flat)\n",
    "\n",
    "clusters = spectral_hg_partitioning(hg, n_clusters = 3, assign_labels='kmeans', n_components=None, random_state=None, n_init=10)\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 0 0 0 0 0 0 1 0 2 2 0 2 2 1 0 0 0 0 1 1 2 1 0 1 0 0 0 0 1 1 0 2 0 0 2\n",
      " 1 2 0 0 0 0 0 0 2 0 0 2 1 2 2 2 2 1 2 2 2 1 1 2 1 2 2 1 0 1 0 0 1 1 1 2 0\n",
      " 1 2 1 0 0 2 1 2 0 1 0 0 1 1 1 1 0 0 2 1 0 2 1 1 0 0 2 1 0 0 2 1 1 2 1 1 2] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.15861031714362883\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "A = np.loadtxt('output/GM12878/AB/A_KR.txt')\n",
    "B = np.loadtxt('output/GM12878/AB/B_KR.txt')\n",
    "# TAD = np.loadtxt('/home/zsc/study/biye/output/chr19_50kb/optics_new.txt')\n",
    "\n",
    "def getClass_AB():\n",
    "    res = np.ones(len(TAD))\n",
    "    for i in range(len(TAD)):\n",
    "        start = TAD[i][0]\n",
    "        end = TAD[i][1]\n",
    "        for j in range(len(A)):\n",
    "            s = A[j][0]\n",
    "            e = A[j][1]\n",
    "            if not (start>e or end<s):\n",
    "                res[i] = 0\n",
    "    return res\n",
    "cos_sim = cosine_similarity(np.vstack((clusters, getClass_AB())))[0,1]\n",
    "print(clusters,getClass_AB())\n",
    "pccs = pearsonr(clusters, getClass_AB())\n",
    "print(cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5791062810152757\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "A1 = np.loadtxt('output/IMR90/sub-compartment/A1.txt')\n",
    "B1 = np.loadtxt('output/IMR90/sub-compartment/B1.txt')\n",
    "A2 = np.loadtxt('output/IMR90/sub-compartment/A2.txt')\n",
    "B2 = np.loadtxt('output/IMR90/sub-compartment/B2.txt')\n",
    "\n",
    "length=[0]*len(TAD)\n",
    "def getlen(fir,sec):\n",
    "    dist = 0\n",
    "    start = fir[0]\n",
    "    end = fir[1]\n",
    "    s = sec[0]\n",
    "    e = sec[1]\n",
    "    if end>s and start<s:\n",
    "        dist = end-s+1\n",
    "    if end>e and start<e:\n",
    "        dist = end-e+1\n",
    "    return dist\n",
    "def getClass_sub():\n",
    "    res = [-1]*len(TAD)\n",
    "    for i in range(len(TAD)):\n",
    "        start = TAD[i][0]\n",
    "        end = TAD[i][1]\n",
    "\n",
    "        for j in range(len(A1)):\n",
    "            s = A1[j][0]\n",
    "            e = A1[j][1]\n",
    "            if not(start>=e or end<=s):\n",
    "                res[i] = 0\n",
    "                if start>s and end<e:\n",
    "                    length[i] = end-start+1\n",
    "                else:\n",
    "                    length[i] = getlen(TAD[i],A1[j])\n",
    "\n",
    "        for j in range(len(A2)):\n",
    "            s = A2[j][0]\n",
    "            e = A2[j][1]\n",
    "            if not(start>=e or end<=s):\n",
    "                if start>=s and end<=e:\n",
    "                        res[i] = 1\n",
    "                        length[i] = end-start+1\n",
    "                else:\n",
    "                    if res[i] ==-1:\n",
    "                        res[i] = 1\n",
    "                        length[i]=getlen(TAD[i],A2[j])\n",
    "                    else:\n",
    "                        if getlen(TAD[i],B1[j])>length[i]:\n",
    "                            length[i] = getlen(TAD[i],A2[j])\n",
    "                            res[i] = 1\n",
    "        for j in range(len(B1)):\n",
    "            s = B1[j][0]\n",
    "            e = B1[j][1]\n",
    "            if not(start>=e or end<=s):\n",
    "                if start>=s and end<=e:\n",
    "                        res[i] = 2\n",
    "                        length[i] = end-start+1\n",
    "                else:\n",
    "                    if res[i] ==-1:\n",
    "                        res[i] = 2\n",
    "                        length[i]=getlen(TAD[i],B1[j])\n",
    "                    else:\n",
    "                        if getlen(TAD[i],B1[j])>length[i]:\n",
    "                            length[i] = getlen(TAD[i],B1[j])\n",
    "                            res[i] = 2\n",
    "        for j in range(len(B2)):\n",
    "            s = B2[j][0]\n",
    "            e = B2[j][1]\n",
    "            if not(start>=e or end<=s):\n",
    "                if start>=s and end<=e:\n",
    "                        res[i] = 3\n",
    "                        length[i] = end-start+1\n",
    "                else:\n",
    "                    if res[i] ==-1:\n",
    "                        res[i] = 3\n",
    "                        length[i]=getlen(TAD[i],B2[j])\n",
    "                    else:\n",
    "                        if getlen(TAD[i],B1[j])>length[i]:\n",
    "                            length[i] = getlen(TAD[i],B2[j])\n",
    "                            res[i] = 3\n",
    "    return res\n",
    "pccs = pearsonr(clusters, getClass_sub())\n",
    "cos_sim = cosine_similarity(np.vstack((clusters, getClass_sub())))[0,1]\n",
    "print(cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_outpath = 'output/IMR90/hypergraph/four/first.txt'\n",
    "two_outpath = 'output/IMR90/hypergraph/four/second.txt'\n",
    "three_outpath = 'output/IMR90/hypergraph/four/three.txt'\n",
    "four_outpath = 'output/IMR90/hypergraph/four/four.txt'\n",
    "with open(one_outpath, \"w\") as out:\n",
    "    for i in range(len(clusters)):\n",
    "        if clusters[i] == 0:\n",
    "            out.write(\"\\t\".join((str(int(TAD[i,0])),str(int(TAD[i][1])))) + \"\\n\")\n",
    "with open(two_outpath, \"w\") as out:\n",
    "    for i in range(len(clusters)):\n",
    "        if clusters[i] == 1:\n",
    "            out.write(\"\\t\".join((str(int(TAD[i,0])),str(int(TAD[i][1])))) + \"\\n\")\n",
    "with open(three_outpath, \"w\") as out:\n",
    "    for i in range(len(clusters)):\n",
    "        if clusters[i] == 2:\n",
    "            out.write(\"\\t\".join((str(int(TAD[i,0])),str(int(TAD[i][1])))) + \"\\n\")\n",
    "with open(four_outpath, \"w\") as out:\n",
    "    for i in range(len(clusters)):\n",
    "        if clusters[i] == 3:\n",
    "            out.write(\"\\t\".join((str(int(TAD[i,0])),str(int(TAD[i][1])))) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard 相似系数: 0.027\n",
      "余弦相似度: 0.0\n",
      "欧几里得距离: 5.385164807134504\n",
      "曼哈顿距离: 29.0\n",
      "pearson: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/pytorch1.7.1/lib/python3.6/site-packages/scipy/stats/stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "/home/user/anaconda3/envs/pytorch1.7.1/lib/python3.6/site-packages/scipy/stats/stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "/home/user/anaconda3/envs/pytorch1.7.1/lib/python3.6/site-packages/scipy/stats/stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "/home/user/anaconda3/envs/pytorch1.7.1/lib/python3.6/site-packages/scipy/stats/stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_score, pairwise_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "\n",
    "first_class = []\n",
    "second_class = []\n",
    "third_class=[]\n",
    "fourth_class=[]\n",
    "def getCluster(i,j):\n",
    "    for i in range(len(clusters)):\n",
    "        if clusters[i]==i:\n",
    "            first_class.append(i)\n",
    "        if clusters[i]==j:\n",
    "            second_class.append(i)\n",
    "    return first_class,second_class\n",
    "res = getClass_AB()\n",
    "pccs,pvalue = pearsonr(clusters, res)\n",
    "def getScore(i,j):\n",
    "    first_class,second_class = getCluster(i,j)\n",
    "    res1 = list(res[first_class])+list(res[second_class])\n",
    "    classes = list(clusters[first_class])+list(clusters[second_class])\n",
    "\n",
    "    jaccard_sim = jaccard_score(classes, res1,average='micro')\n",
    "    cos_sim = cosine_similarity(np.vstack((classes, res1)))[0,1]\n",
    "    euclidean_dist = euclidean_distances(np.vstack((classes, res1)))[0,1]\n",
    "    manhattan_dist = manhattan_distances(np.vstack((classes, res1)))[0,1]\n",
    "    per,pvalue = pearsonr(classes, res1)\n",
    "    return jaccard_sim,cos_sim,euclidean_dist,manhattan_dist,per\n",
    "\n",
    "a = getScore(0,1)\n",
    "b = getScore(0,2)\n",
    "c = getScore(1,2)\n",
    "jaccard_sim = max(a[0],b[0],c[0])\n",
    "cos_sim = max(a[1],b[1],c[1])\n",
    "euclidean_dist = min(a[2],b[2],c[2])\n",
    "manhattan_dist = min(a[3],b[3],c[3])\n",
    "per = c[4]\n",
    "print(\"Jaccard 相似系数: %0.3f\"%(jaccard_sim))\n",
    "print(\"余弦相似度:\", cos_sim)\n",
    "print(\"欧几里得距离:\", euclidean_dist)\n",
    "print(\"曼哈顿距离:\", manhattan_dist)\n",
    "print(\"pearson:\",per)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard 相似系数: 0.055\n",
      "余弦相似度: 0.5791062810152757\n",
      "欧几里得距离: 16.1245154965971\n",
      "曼哈顿距离: 156.0\n",
      "pearson: 0.1423555839674722\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_score, pairwise_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "\n",
    "res = getClass_sub()\n",
    "pccs,pvalue = pearsonr(clusters, res)\n",
    "\n",
    "jaccard_sim = jaccard_score(clusters, res,average='micro')\n",
    "cos_sim = cosine_similarity(np.vstack((clusters, res)))[0,1]\n",
    "euclidean_dist = euclidean_distances(np.vstack((clusters, res)))[0,1]\n",
    "manhattan_dist = manhattan_distances(np.vstack((clusters, res)))[0,1]\n",
    "per,pvalue = pearsonr(clusters, res)\n",
    "print(\"Jaccard 相似系数: %0.3f\"%(jaccard_sim))\n",
    "print(\"余弦相似度:\", cos_sim)\n",
    "print(\"欧几里得距离:\", euclidean_dist)\n",
    "print(\"曼哈顿距离:\", manhattan_dist)\n",
    "print(\"pearson:\",per)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4274494bb6e4d31f50240a0c04a6a989ecf29030e4e3a4cc50f3a848fd95421"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
